# -*- coding: utf-8 -*-
"""Final Task_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vntKLJiNSGprEgSOR7sDMobTeb8BPZs_

# IMPORT LIBRARY
"""

from google.colab import drive
drive.mount("/content/gdrive")

import pandas as pd
import numpy as np


#Pemodelan
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX


#Visualisasi
import matplotlib.pyplot as plt

from sklearn.metrics import mean_squared_error
from statsmodels.tools.eval_measures import rmse

"""# LOAD DATA"""

d_transaksi = pd.read_csv("/content/gdrive/MyDrive/Data Sheet/Case Study - Transaction.csv", delimiter=';')
d_transaksi.head()

d_cs= pd.read_csv("/content/gdrive/MyDrive/Data Sheet/Case Study - Customer.csv", delimiter=";")
d_cs.head()

d_produk = pd.read_csv("/content/gdrive/MyDrive/Data Sheet/Case Study - Product.csv", delimiter=";")
d_produk.head()

d_store = pd.read_csv("/content/gdrive/MyDrive/Data Sheet/Case Study - Store.csv", delimiter=";")
d_store.head()

"""#DATA CLEANSING"""

data_info = [d_transaksi, d_cs, d_produk, d_store]

for i in data_info:
  display(i.info())
  print("\n")

d_transaksi['Date'] = pd.to_datetime(d_transaksi['Date'])
d_cs['Income'] = d_cs['Income'].str.replace(',', '').astype(int)

"""#DATA MERGE"""

merged_data = pd.merge(d_transaksi, d_cs, on='CustomerID')

merged_data = pd.merge(merged_data, d_produk, on='ProductID')

merged_data = pd.merge(merged_data, d_store, on='StoreID')

merged_data

grouped_data = merged_data.groupby('Date')['Qty'].sum().reset_index()
grouped_data.head()

grouped_data.info()

# Memastikan tanggal dalam urutan waktu yang benar
grouped_data = grouped_data.sort_index()

# Menentukan frekuensi harian
grouped_data.index.freq = 'D'

plt.figure(figsize=(18,9))
plt.plot(grouped_data.index, grouped_data["Qty"], linestyle="-")
plt.xlabel=('Dates')
plt.ylabel=('Total Kuantitas')
plt.show();

"""# METODE TIME SERIES ARIMA"""

train_data = grouped_data[:len(grouped_data)-12]
test_data = grouped_data[len(grouped_data)-12:]

#train_ratio = 0.7
#test_ratio = 0.3

#split_index = int(len(grouped_data) * train_ratio)

#train_data = grouped_data[:split_index]
#test_data = grouped_data[split_index:]

arima_model = SARIMAX(train_data['Qty'], order = (1,1,1), seasonal_order = (4,0,3,7))
arima_result = arima_model.fit()
arima_result.summary()

arima_pred = arima_result.predict(start = len(train_data), end = len(grouped_data)-1, typ="levels").rename("ARIMA Predictions")
arima_pred

test_data['Qty'].plot(figsize = (16,5), legend=True)
arima_pred.plot(legend = True);

arima_rmse_error = rmse(test_data['Qty'], arima_pred)
arima_mse_error = arima_rmse_error**2
mean_value = grouped_data['Qty'].mean()

print(f'MSE Error: {arima_mse_error}\nRMSE Error: {arima_rmse_error}\nMean: {mean_value}')

test_data['ARIMA_Predictions'] = arima_pred

test_data

# Prediksi Kuantitas Harian
forecast_steps = 19  # Jumlah hari yang ingin diprediksi
forecast = arima_result.forecast(steps=forecast_steps)

# Tampilkan hasil prediksi
forecast= pd.DataFrame(forecast)

forecast["predicted_mean"] = forecast["predicted_mean"].astype(int)

forecast.tail(7)